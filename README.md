# LightArcNet

##Abstract
Human activity recognition is using technology, often through machine learning and sensor data, to identify and classify specific actions or behaviors performed by individuals. Activity recognition from sensor data plays a crucial role in various domains, including healthcare and human-computer interaction. This paper introduces LightActNet, a Lightweight Activity Recognition Network, an innovative lightweight hybrid architecture that seamlessly integrates Convolutional Neural Networks and Long Short-Term Memory networks to enhance the accuracy and efficiency of activity recognition systems. The proposed architecture leverages the spatial hierarchies captured by CNNs and the temporal dependencies modelled by LSTMs. The model achieves a lightweight footprint through careful design considerations without compromising performance. The CNN component adeptly extracts relevant spatial features from raw sensor data, facilitating the discernment of intricate patterns and spatial relationships. The LSTM component then processes the temporal sequences of feature maps, capturing long-range dependencies over time. Two benchmark datasets, i.e., WISDM and UCI-HAR, are utilized to evaluate the model performance. The proposed LightActNet approach achieved an accuracy of 99.42\% on WISDM and 96.61\% on UCI-HAR datasets and with few model parameters. Experimental results showcase the model's superior accuracy and robustness compared to existing state-of-the-art approaches. The lightweight architecture makes it suitable for edge computing applications, enabling efficient activity recognition on edge devices.
